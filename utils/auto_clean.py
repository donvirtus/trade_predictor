#!/usr/bin/env python3
"""
Auto-Clean Script for Trading System Automation

Removes all files generated by automation system to enable fresh testing from zero.
Provides both interactive and command-line interfaces for safe cleanup.

Usage:
    python utils/auto_clean.py                    # Interactive mode
    python utils/auto_clean.py --all              # Clean everything
    python utils/auto_clean.py --models-only      # Only models
    python utils/auto_clean.py --data-only        # Only data/configs
    python utils/auto_clean.py --verify           # Show what would be deleted
    
Features:
    - Safe cleanup with confirmation prompts
    - Selective cleaning options
    - Verification mode (dry-run)
    - Comprehensive cleanup of all automation artifacts
    - Recovery guidance for accidental deletion
"""

import os
import sys
import glob
import argparse
from pathlib import Path
from typing import List, Dict, Set
from datetime import datetime

# Add project root
ROOT = os.path.abspath(os.path.join(os.path.dirname(__file__), '..'))
sys.path.insert(0, ROOT)

class AutoCleanManager:
    """
    Comprehensive cleanup manager for automation-generated files
    """
    
    def __init__(self, project_root: str = None):
        self.project_root = Path(project_root or ROOT)
        self.cleanup_categories = self._define_cleanup_categories()
        self.safety_checks = True
        
    def _define_cleanup_categories(self) -> Dict[str, Dict]:
        """Define all categories of files that can be cleaned"""
        return {
            "models": {
                "description": "üß† Machine Learning Models & Metadata",
                "paths": [
                    "models/tree_models/*.txt",
                    "models/tree_models/*.joblib", 
                    "models/metadata/*.json",
                    "models/ensemble_models/*",
                    "models/lstm_models/*",
                    "models/timeseries_models/*"
                ],
                "critical": True,
                "size_estimate": "5-50 MB"
            },
            
            "databases": {
                "description": "üóÑÔ∏è Generated Databases",
                "paths": [
                    "data/db/*.sqlite",
                    "data/test_db/*.sqlite"
                ],
                "critical": True,
                "size_estimate": "10-500 MB"
            },
            
            "auto_configs": {
                "description": "üéØ Auto-Generated Configurations",
                "paths": [
                    "data/auto_balanced_thresholds.json",
                    "data/threshold_optimal_summary.json", 
                    "data/threshold_validation_results.csv"
                ],
                "critical": False,
                "size_estimate": "< 1 MB"
            },
            
            "validation_reports": {
                "description": "üìä Validation & Analysis Reports",
                "paths": [
                    "data/threshold_validation_report_*.json",
                    "data/analysis_auto_vs_manual_thresholds.json"
                ],
                "critical": False,
                "size_estimate": "< 1 MB"
            },
            
            "cache_files": {
                "description": "üß† Cache & Temporary Files",
                "paths": [
                    "data/adaptive_multipliers_cache*.json",
                    "data/enhanced_predictions_*.sqlite",
                    "catboost_info/*"
                ],
                "critical": False,
                "size_estimate": "< 5 MB"
            },
            
            "logs": {
                "description": "üìù Log Files",
                "paths": [
                    "data/logs/*.log"
                ],
                "critical": False,
                "size_estimate": "< 10 MB"
            },
            
            "plots": {
                "description": "üìà Generated Plots & Visualizations",
                "paths": [
                    "data/plots/*"
                ],
                "critical": False,
                "size_estimate": "< 5 MB"
            }
        }
    
    def scan_files(self, categories: List[str] = None) -> Dict[str, List[Path]]:
        """
        Scan for files in specified categories
        
        Args:
            categories: List of category names to scan. If None, scan all.
            
        Returns:
            Dict mapping category names to lists of found files
        """
        if categories is None:
            categories = list(self.cleanup_categories.keys())
        
        found_files = {}
        
        for category in categories:
            if category not in self.cleanup_categories:
                print(f"‚ö†Ô∏è  Unknown category: {category}")
                continue
                
            category_info = self.cleanup_categories[category]
            category_files = []
            
            for pattern in category_info["paths"]:
                full_pattern = self.project_root / pattern
                matches = glob.glob(str(full_pattern))
                category_files.extend([Path(match) for match in matches])
            
            # Remove duplicates and sort
            category_files = sorted(list(set(category_files)))
            found_files[category] = category_files
        
        return found_files
    
    def estimate_cleanup_impact(self, categories: List[str] = None) -> Dict:
        """
        Estimate the impact of cleanup operation
        
        Returns:
            Dict with file counts, sizes, and safety information
        """
        found_files = self.scan_files(categories)
        
        total_files = 0
        total_size = 0
        critical_categories = []
        
        impact = {
            "categories": {},
            "summary": {
                "total_files": 0,
                "total_size_mb": 0,
                "critical_categories": [],
                "safe_to_clean": True
            }
        }
        
        for category, files in found_files.items():
            category_info = self.cleanup_categories[category]
            
            # Calculate size
            category_size = 0
            for file_path in files:
                if file_path.exists():
                    category_size += file_path.stat().st_size
            
            impact["categories"][category] = {
                "description": category_info["description"],
                "file_count": len(files),
                "size_mb": category_size / (1024 * 1024),
                "critical": category_info["critical"],
                "files": [str(f) for f in files]
            }
            
            total_files += len(files)
            total_size += category_size
            
            if category_info["critical"] and len(files) > 0:
                critical_categories.append(category)
        
        impact["summary"]["total_files"] = total_files
        impact["summary"]["total_size_mb"] = total_size / (1024 * 1024)
        impact["summary"]["critical_categories"] = critical_categories
        impact["summary"]["safe_to_clean"] = len(critical_categories) == 0 or not self.safety_checks
        
        return impact
    
    def clean_categories(self, categories: List[str], dry_run: bool = False) -> Dict:
        """
        Clean specified categories
        
        Args:
            categories: List of category names to clean
            dry_run: If True, don't actually delete files
            
        Returns:
            Dict with cleanup results
        """
        found_files = self.scan_files(categories)
        
        results = {
            "deleted_files": [],
            "failed_deletions": [],
            "total_deleted": 0,
            "total_failed": 0,
            "dry_run": dry_run
        }
        
        for category, files in found_files.items():
            print(f"\nüóÇÔ∏è  Cleaning {category}: {self.cleanup_categories[category]['description']}")
            
            for file_path in files:
                try:
                    if file_path.exists():
                        if dry_run:
                            print(f"   [DRY-RUN] Would delete: {file_path}")
                            results["deleted_files"].append(str(file_path))
                        else:
                            if file_path.is_file():
                                file_path.unlink()
                                print(f"   ‚úÖ Deleted: {file_path}")
                                results["deleted_files"].append(str(file_path))
                            elif file_path.is_dir():
                                import shutil
                                shutil.rmtree(file_path)
                                print(f"   ‚úÖ Deleted directory: {file_path}")
                                results["deleted_files"].append(str(file_path))
                        
                        results["total_deleted"] += 1
                        
                except Exception as e:
                    print(f"   ‚ùå Failed to delete {file_path}: {e}")
                    results["failed_deletions"].append({"file": str(file_path), "error": str(e)})
                    results["total_failed"] += 1
        
        return results
    
    def interactive_cleanup(self):
        """Interactive cleanup with user confirmations"""
        print("üßπ" + "="*80)
        print("ü§ñ AUTOMATED SYSTEM CLEANUP - Interactive Mode")
        print("="*80)
        print()
        
        # Scan all files
        impact = self.estimate_cleanup_impact()
        
        # Show impact summary
        print("üìä CLEANUP IMPACT ANALYSIS:")
        print("-" * 50)
        print(f"Total files found: {impact['summary']['total_files']}")
        print(f"Total size: {impact['summary']['total_size_mb']:.1f} MB")
        
        if impact["summary"]["critical_categories"]:
            print(f"‚ö†Ô∏è  Critical categories: {', '.join(impact['summary']['critical_categories'])}")
        
        print()
        
        # Show by category
        for category, info in impact["categories"].items():
            if info["file_count"] > 0:
                critical_mark = " ‚ö†Ô∏è CRITICAL" if info["critical"] else ""
                print(f"{info['description']}: {info['file_count']} files ({info['size_mb']:.1f} MB){critical_mark}")
        
        print()
        
        # Category selection
        print("üéØ SELECT CLEANUP SCOPE:")
        print("1. üßπ Clean ALL (complete reset)")
        print("2. üß† Models only (keep data)")
        print("3. üóÑÔ∏è  Data only (keep models)")
        print("4. üéØ Configs & reports only (safe)")
        print("5. üìù Logs & cache only (safest)")
        print("6. üîç Custom selection")
        print("0. ‚ùå Cancel")
        
        choice = input("\nSelect option (0-6): ").strip()
        
        if choice == "0":
            print("‚ùå Cleanup cancelled.")
            return
        elif choice == "1":
            categories = list(self.cleanup_categories.keys())
            scope_name = "ALL AUTOMATION FILES"
        elif choice == "2":
            categories = ["models"]
            scope_name = "MODELS ONLY"
        elif choice == "3":
            categories = ["databases", "auto_configs", "validation_reports", "cache_files"]
            scope_name = "DATA ONLY"
        elif choice == "4":
            categories = ["auto_configs", "validation_reports"]
            scope_name = "CONFIGS & REPORTS"
        elif choice == "5":
            categories = ["logs", "cache_files", "plots"]
            scope_name = "LOGS & CACHE"
        elif choice == "6":
            categories = self._custom_category_selection()
            scope_name = "CUSTOM SELECTION"
        else:
            print("‚ùå Invalid choice.")
            return
        
        if not categories:
            print("‚ùå No categories selected.")
            return
        
        # Final confirmation
        print(f"\n‚ö†Ô∏è  FINAL CONFIRMATION:")
        print(f"Scope: {scope_name}")
        print(f"Categories: {', '.join(categories)}")
        
        # Re-scan selected categories
        selected_impact = self.estimate_cleanup_impact(categories)
        print(f"Files to delete: {selected_impact['summary']['total_files']}")
        print(f"Size: {selected_impact['summary']['total_size_mb']:.1f} MB")
        
        confirm = input("\nüö® Are you ABSOLUTELY SURE? (type 'YES' to confirm): ").strip()
        
        if confirm != "YES":
            print("‚ùå Cleanup cancelled.")
            return
        
        # Execute cleanup
        print(f"\nüöÄ Starting cleanup of {scope_name}...")
        results = self.clean_categories(categories, dry_run=False)
        
        # Show results
        print(f"\n‚úÖ CLEANUP COMPLETED!")
        print(f"Files deleted: {results['total_deleted']}")
        print(f"Failed deletions: {results['total_failed']}")
        
        if results["total_failed"] > 0:
            print(f"\n‚ùå FAILED DELETIONS:")
            for failure in results["failed_deletions"]:
                print(f"   {failure['file']}: {failure['error']}")
        
        print(f"\nüí° To rebuild system: python utils/auto_pipeline.py")
    
    def _custom_category_selection(self) -> List[str]:
        """Allow user to select specific categories"""
        print("\nüìã AVAILABLE CATEGORIES:")
        
        available_categories = list(self.cleanup_categories.keys())
        for i, category in enumerate(available_categories, 1):
            info = self.cleanup_categories[category]
            critical_mark = " ‚ö†Ô∏è" if info["critical"] else ""
            print(f"{i}. {info['description']}{critical_mark}")
        
        print("\nEnter category numbers (comma-separated, e.g., 1,3,5):")
        selection = input("Categories: ").strip()
        
        if not selection:
            return []
        
        try:
            indices = [int(x.strip()) - 1 for x in selection.split(",")]
            selected = [available_categories[i] for i in indices if 0 <= i < len(available_categories)]
            return selected
        except (ValueError, IndexError):
            print("‚ùå Invalid selection.")
            return []


def main():
    """CLI interface for auto-clean"""
    parser = argparse.ArgumentParser(
        description='Auto-Clean Script for Trading System Automation',
        formatter_class=argparse.RawDescriptionHelpFormatter,
        epilog="""
Examples:
  python utils/auto_clean.py                    # Interactive mode
  python utils/auto_clean.py --all              # Clean everything
  python utils/auto_clean.py --models-only      # Only models
  python utils/auto_clean.py --data-only        # Only data/configs
  python utils/auto_clean.py --verify           # Show what would be deleted
  
Safety:
  - Use --verify first to see what would be deleted
  - Critical files (models, databases) require confirmation
  - All operations can be undone by rebuilding with auto_pipeline.py
        """
    )
    
    parser.add_argument('--all', action='store_true',
                       help='Clean all automation-generated files')
    parser.add_argument('--models-only', action='store_true',
                       help='Clean only models and metadata')
    parser.add_argument('--data-only', action='store_true',
                       help='Clean only data files (databases, configs)')
    parser.add_argument('--safe-only', action='store_true',
                       help='Clean only safe files (logs, cache, reports)')
    parser.add_argument('--verify', action='store_true',
                       help='Show what would be deleted (dry-run)')
    parser.add_argument('--force', action='store_true',
                       help='Skip safety confirmations')
    parser.add_argument('--categories', nargs='+',
                       help='Specific categories to clean')
    
    args = parser.parse_args()
    
    # Create cleaner
    cleaner = AutoCleanManager()
    
    if args.force:
        cleaner.safety_checks = False
    
    # Interactive mode if no specific options
    if not any([args.all, args.models_only, args.data_only, args.safe_only, args.verify, args.categories]):
        cleaner.interactive_cleanup()
        return
    
    # Determine categories
    if args.all:
        categories = list(cleaner.cleanup_categories.keys())
        scope_name = "ALL"
    elif args.models_only:
        categories = ["models"]
        scope_name = "MODELS ONLY"
    elif args.data_only:
        categories = ["databases", "auto_configs", "validation_reports", "cache_files"]
        scope_name = "DATA ONLY"
    elif args.safe_only:
        categories = ["logs", "cache_files", "plots"]
        scope_name = "SAFE FILES"
    elif args.categories:
        categories = args.categories
        scope_name = "CUSTOM"
    else:
        categories = list(cleaner.cleanup_categories.keys())
        scope_name = "ALL"
    
    # Show impact
    impact = cleaner.estimate_cleanup_impact(categories)
    
    print(f"üßπ AUTO-CLEAN SCOPE: {scope_name}")
    print("=" * 50)
    print(f"Files to process: {impact['summary']['total_files']}")
    print(f"Total size: {impact['summary']['total_size_mb']:.1f} MB")
    
    if impact["summary"]["critical_categories"]:
        print(f"‚ö†Ô∏è  Critical categories: {', '.join(impact['summary']['critical_categories'])}")
    
    # Execute
    dry_run = args.verify
    if dry_run:
        print(f"\nüîç DRY-RUN MODE - Showing what would be deleted:")
    else:
        print(f"\nüöÄ Executing cleanup...")
    
    results = cleaner.clean_categories(categories, dry_run=dry_run)
    
    print(f"\n‚úÖ OPERATION COMPLETED!")
    if dry_run:
        print(f"Would delete: {results['total_deleted']} files")
    else:
        print(f"Deleted: {results['total_deleted']} files")
        print(f"Failed: {results['total_failed']} files")
        
        if results["total_deleted"] > 0:
            print(f"\nüí° To rebuild: python utils/auto_pipeline.py")


if __name__ == '__main__':
    main()